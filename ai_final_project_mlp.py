# -*- coding: utf-8 -*-
"""AI_Final_Project_MLP

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/19iJGZd-a579Llzq0t09XGqGy1yYS9Vm5
"""

import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MinMaxScaler
from keras.models import Sequential
from keras.layers import Dense
from keras.optimizers import Adam
import matplotlib.pyplot as plt
import pandas as pd



# Load the data from a URL
def LoadingData(url):
    df = pd.read_csv(url)
    # Extract the closing prices to make it simple
    data = df['Close'].values
    return data

# Preprocess the data
def PreprocessData(data):
    scaler = MinMaxScaler()
    data_scaled = scaler.fit_transform(data.reshape(-1, 1))

    return data_scaled, scaler

# Split the data into training and testing sets
def SplitingData(data):
    X = data[:-1]  # Features
    y = data[1:]   # Target is the next data point

    # Making the split my having the test set being 20% of the whole set
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

    return X_train, X_test, y_train, y_test

# Build the MLP model
def BuildingModel(input_size):
    model = Sequential()
    model.add(Dense(64, input_dim=input_size, activation='relu'))
    model.add(Dense(32, activation='relu'))
    model.add(Dense(1, activation='linear'))  # Output layer

    optimizer = Adam(learning_rate=0.001)
    model.compile(optimizer=optimizer, loss='mean_squared_error') #The difference between the actual and predicted

    return model

# Training the model
def Training(model, X_train, y_train, epochs=50, batch_size=32):
    model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, verbose=1)
    #The epcoh and batch sizes are just regular standards

# Evaluating the model and creating the graph
def Evaluating(model, X_test, y_test, scaler):
    predictions = model.predict(X_test)
    predictions = scaler.inverse_transform(predictions)  # Inverse transform to get original scale to compare to the graph
    y_test_orig = scaler.inverse_transform(y_test.reshape(-1, 1))
    plt.figure(figsize=(10, 6))
    plt.plot(y_test_orig, label='Actual Amazon Stock Prices')
    plt.plot(predictions, label='Predicted Amazon Stock Prices')
    plt.title('Amazon Stock Price Prediction')
    plt.xlabel('Date')
    plt.ylabel('Stock Price')
    plt.legend()
    plt.show()
    loss = model.evaluate(X_test, y_test)
    print(f'Mean Squared Error on Test Set: {loss}')

    return predictions

# Load stock price data from a URL
  stock_data_url = 'https://raw.githubusercontent.com/CeeBee99/AI_Final_Project/main/AMZN(training).csv'
  stock_data = LoadingData(stock_data_url)

  # Preprocess the data
  processed_data, scaler = PreprocessData(stock_data)

  # Split the data
  X_train, X_test, y_train, y_test = SplitingData(processed_data)

  # Build the MLP model
  input_size = 1  # Since we only have one feature (closing price)
  model = BuildingModel(input_size)

  # Train the model
  Training(model, X_train, y_train)

  # Evaluate the model and display predictions with a graph
  predictions = Evaluating(model, X_test, y_test, scaler)


  print("Predictions:", predictions)